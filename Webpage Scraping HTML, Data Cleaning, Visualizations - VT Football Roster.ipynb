{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258da55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import altair as alt\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# notebook renderer for Altair\n",
    "renderer = \"default\"\n",
    "alt.renderers.enable(renderer)\n",
    "\n",
    "URL = \"https://hokiesports.com/sports/football/roster/season/2025-26\"\n",
    "HTML_FILE = \"vt-football-roster-2025-26.html\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0c5cea",
   "metadata": {},
   "source": [
    "# Virginia Tech Football Roster (2025–26): HTML Webscrape, Data Clean, and Analysis\n",
    "\n",
    "This notebook mirrors the structure of the original UGA roster project, but targets the Virginia Tech roster page:\n",
    "\n",
    "- Scrape roster **cards** from the HokieSports roster page HTML (not a simple `<table>`).\n",
    "- Build a tidy pandas DataFrame (player name, position, class/year, height, weight, hometown, high school, player URL).\n",
    "- Clean and transform fields (height → inches, weight classes, BMI).\n",
    "- Explore quick counts and create a few basic visuals.\n",
    "\n",
    "> **Tip:** If the site changes its HTML structure, the scraping section may need small selector tweaks. Keeping the parsing logic in a few helper functions makes that painless.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20526cef",
   "metadata": {},
   "source": [
    "### Extracting the roster cards from the HTML page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8408f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the roster page HTML and save it locally (so you can re-run parsing without re-downloading)\n",
    "response = requests.get(URL, headers=HEADERS, timeout=30)\n",
    "response.raise_for_status()\n",
    "\n",
    "with open(HTML_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "response.status_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe7f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_spaces(s: str) -> str:\n",
    "    \"\"\"Collapse repeated whitespace and strip.\"\"\"\n",
    "    return re.sub(r\"\\s+\", \" \", (s or \"\").strip())\n",
    "\n",
    "def _parse_height_weight_year(text: str):\n",
    "    \"\"\"\n",
    "    Parse year/class, height, and weight from a blob of card text.\n",
    "\n",
    "    Returns:\n",
    "      (year, height_str '6-2', height_inches, weight_lbs)\n",
    "    \"\"\"\n",
    "    t = _clean_spaces(text)\n",
    "\n",
    "    # year/class (optional)\n",
    "    year = None\n",
    "    m_year = re.search(\n",
    "        r\"\\b(Graduate|Senior|Junior|Sophomore|Freshman|Redshirt\\s+(?:Senior|Junior|Sophomore|Freshman))\\b\",\n",
    "        t,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "    if m_year:\n",
    "        year = m_year.group(1).title()\n",
    "\n",
    "    # height supports unicode primes (′ ″) and normal ' / \"\n",
    "    m_h = re.search(r\"(\\d+)\\s*[′']\\s*(\\d+)\\s*[″\\\"]\", t)\n",
    "    height_str = None\n",
    "    height_in = np.nan\n",
    "    if m_h:\n",
    "        ft = int(m_h.group(1))\n",
    "        inch = int(m_h.group(2))\n",
    "        height_str = f\"{ft}-{inch}\"\n",
    "        height_in = ft * 12 + inch\n",
    "\n",
    "    # weight: \"195 lbs\"\n",
    "    m_w = re.search(r\"(\\d+)\\s*lbs\\b\", t, flags=re.IGNORECASE)\n",
    "    weight = np.nan\n",
    "    if m_w:\n",
    "        weight = int(m_w.group(1))\n",
    "\n",
    "    return year, height_str, height_in, weight\n",
    "\n",
    "POSITION_OPTIONS = [\n",
    "    \"Offensive Line\",\n",
    "    \"Defensive Line\",\n",
    "    \"Defensive Back\",\n",
    "    \"Wide Receiver\",\n",
    "    \"Running Back\",\n",
    "    \"Quarterback\",\n",
    "    \"Linebacker\",\n",
    "    \"Tight End\",\n",
    "    \"Kicker\",\n",
    "    \"Punter\",\n",
    "    \"Long Snapper\",\n",
    "]\n",
    "\n",
    "def _match_position_prefix(s: str):\n",
    "    s = _clean_spaces(s)\n",
    "    for pos in sorted(POSITION_OPTIONS, key=len, reverse=True):\n",
    "        if s.lower().startswith(pos.lower()):\n",
    "            return pos, _clean_spaces(s[len(pos):])\n",
    "    return None, s\n",
    "\n",
    "def _parse_home_line(text: str):\n",
    "    \"\"\"\n",
    "    Attempt to split a roster card line into:\n",
    "      Position, City, State, High School\n",
    "\n",
    "    Many cards look like:\n",
    "      \"Defensive Back Virginia Beach, Va. Green Run\"\n",
    "    \"\"\"\n",
    "    t = _clean_spaces(text)\n",
    "    position, remainder = _match_position_prefix(t)\n",
    "    remainder = _clean_spaces(remainder)\n",
    "\n",
    "    city = state = high_school = None\n",
    "\n",
    "    if \",\" in remainder:\n",
    "        city_part, rest = remainder.split(\",\", 1)\n",
    "        city = _clean_spaces(city_part)\n",
    "        rest = _clean_spaces(rest)\n",
    "\n",
    "        # State like \"Va.\" or \"N.J.\" then the rest is the HS\n",
    "        m = re.match(r\"^(?P<state>(?:[A-Za-z]\\.[A-Za-z]\\.|[A-Za-z]{2,10}\\.))\\s*(?P<hs>.*)$\", rest)\n",
    "        if m:\n",
    "            state = _clean_spaces(m.group(\"state\"))\n",
    "            high_school = _clean_spaces(m.group(\"hs\")) if m.group(\"hs\") else None\n",
    "        else:\n",
    "            parts = rest.split(\" \", 1)\n",
    "            state = _clean_spaces(parts[0]) if parts else None\n",
    "            high_school = _clean_spaces(parts[1]) if len(parts) > 1 else None\n",
    "\n",
    "    return position, city, state, high_school\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bc2e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the saved HTML and parse roster cards\n",
    "text = open(HTML_FILE, \"r\", encoding=\"utf-8\").read()\n",
    "soup = BeautifulSoup(text, \"html.parser\")\n",
    "\n",
    "# Player links typically include /player/ in the href\n",
    "player_links = soup.select('a[href*=\"/sports/football/roster/season/2025-26/player/\"]')\n",
    "\n",
    "seen = set()\n",
    "rows = []\n",
    "\n",
    "for a in player_links:\n",
    "    href = a.get(\"href\")\n",
    "    if not href or href in seen:\n",
    "        continue\n",
    "    seen.add(href)\n",
    "\n",
    "    card = a.find_parent([\"li\", \"article\", \"div\"])\n",
    "    if card is None:\n",
    "        continue\n",
    "\n",
    "    # A compact text blob for parsing\n",
    "    card_texts = list(card.stripped_strings)\n",
    "    blob = _clean_spaces(\" \".join(card_texts))\n",
    "\n",
    "    name = _clean_spaces(a.get_text(strip=True))\n",
    "\n",
    "    year, height_str, height_in, weight = _parse_height_weight_year(blob)\n",
    "\n",
    "    # Pick a line with a comma (often the hometown/state line)\n",
    "    home_candidate = None\n",
    "    for s in card_texts:\n",
    "        if \",\" in s:\n",
    "            home_candidate = s\n",
    "\n",
    "    position = city = state = high_school = None\n",
    "    if home_candidate:\n",
    "        position, city, state, high_school = _parse_home_line(home_candidate)\n",
    "\n",
    "    rows.append({\n",
    "        \"Name\": name,\n",
    "        \"Position\": position,\n",
    "        \"Class\": year,\n",
    "        \"Height\": height_str,\n",
    "        \"Weight\": weight,\n",
    "        \"Height, inches\": height_in,\n",
    "        \"City\": city,\n",
    "        \"State\": state,\n",
    "        \"High School\": high_school,\n",
    "        \"Player URL\": (\"https://hokiesports.com\" + href) if href.startswith(\"/\") else href,\n",
    "        \"Raw Card Text\": blob,   # keep for debugging; drop when satisfied\n",
    "    })\n",
    "\n",
    "data = pd.DataFrame(rows)\n",
    "\n",
    "# basic type cleanup\n",
    "data[\"Weight\"] = pd.to_numeric(data[\"Weight\"], errors=\"coerce\")\n",
    "data[\"Height, inches\"] = pd.to_numeric(data[\"Height, inches\"], errors=\"coerce\")\n",
    "\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9809201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview\n",
    "data.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6e3d99",
   "metadata": {},
   "source": [
    "## Data Exploration and Cleaning\n",
    "\n",
    "Below: exploring the data, dealing with nulls, resetting the index, standardizing column names, splitting the hometown line into `City`, `State`, and `High School`, and converting height to inches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf98d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates by Player URL and reset the index\n",
    "data = data.drop_duplicates(subset=[\"Player URL\"]).reset_index(drop=True)\n",
    "\n",
    "# Optional: drop the raw text once you're happy with parsing\n",
    "# data = data.drop(columns=[\"Raw Card Text\"])\n",
    "\n",
    "# Missingness overview\n",
    "data.isna().sum().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e7c74a",
   "metadata": {},
   "source": [
    "#### Checking for duplicates (Player URL, Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323e8830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to check whether a column has duplicates\n",
    "def dups_check(df, col):\n",
    "    if df[col].nunique(dropna=False) < df.shape[0]:\n",
    "        print(f\"There are duplicate entries in `{col}`\")\n",
    "    else:\n",
    "        print(f\"All values in `{col}` are unique\")\n",
    "\n",
    "dups_check(data, \"Player URL\")\n",
    "dups_check(data, \"Name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b99dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts of players by class/year and position\n",
    "class_counts = data.groupby(\"Class\")[\"Name\"].count().sort_values(ascending=False).to_dict()\n",
    "position_counts = data.groupby(\"Position\")[\"Name\"].count().sort_values(ascending=False).to_dict()\n",
    "\n",
    "class_counts, position_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec2ca26",
   "metadata": {},
   "source": [
    "## Data Transformation\n",
    "\n",
    "Below: classifying weight as `Heavy`, `Average`, and `Light`, plus creating a `BMI` column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ed5f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight class function (same idea as the UGA project)\n",
    "def weight_class(weight):\n",
    "    if pd.isna(weight):\n",
    "        return \"N/A\"\n",
    "    if weight > 270:\n",
    "        return \"Heavy\"\n",
    "    if weight < 220:\n",
    "        return \"Light\"\n",
    "    if 220 <= weight <= 270:\n",
    "        return \"Average\"\n",
    "    return \"N/A\"\n",
    "\n",
    "data[\"Weight Class\"] = data[\"Weight\"].apply(weight_class)\n",
    "\n",
    "# BMI (only if height + weight exist)\n",
    "data[\"BMI\"] = np.where(\n",
    "    (~data[\"Weight\"].isna()) & (~data[\"Height, inches\"].isna()) & (data[\"Height, inches\"] > 0),\n",
    "    np.round((703 * data[\"Weight\"]) / (data[\"Height, inches\"] ** 2), 2),\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "data[[\"Name\", \"Position\", \"Class\", \"Height\", \"Weight\", \"Height, inches\", \"Weight Class\", \"BMI\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4ece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMI categories (same thresholds as the UGA notebook)\n",
    "categories = {\"Overweight\": 0, \"Normal\": 0, \"Underweight\": 0}\n",
    "\n",
    "for v in data[\"BMI\"].dropna():\n",
    "    if v >= 25:\n",
    "        categories[\"Overweight\"] += 1\n",
    "    elif v >= 18.5:\n",
    "        categories[\"Normal\"] += 1\n",
    "    else:\n",
    "        categories[\"Underweight\"] += 1\n",
    "\n",
    "categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e530f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group players that share a last name (same idea as UGA notebook)\n",
    "names = {}\n",
    "for nm in data[\"Name\"].dropna():\n",
    "    parts = nm.split()\n",
    "    if len(parts) < 2:\n",
    "        continue\n",
    "    ln = parts[-1]\n",
    "    names.setdefault(ln, []).append(nm)\n",
    "\n",
    "same_last_names = [tuple(v) for v in names.values() if len(v) > 1]\n",
    "same_last_names = sorted(same_last_names, key=lambda x: (-len(x), x[0].split()[-1]))\n",
    "same_last_names[:15]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c064c45e",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "Here, I show quick trends and insights from the dataset. I also exclude players missing height or weight for the height/weight/BMI plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d4e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude missing height/weight for plots\n",
    "data2 = data[(data[\"Weight Class\"] != \"N/A\") & (~data[\"Weight\"].isna()) & (~data[\"Height, inches\"].isna())].copy()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 5), sharey=False)\n",
    "\n",
    "colors = {\"Heavy\": \"darkblue\", \"Average\": \"blue\", \"Light\": \"lightblue\"}\n",
    "\n",
    "ax[0].scatter(data2[\"Height, inches\"], data2[\"Weight\"], c=data2[\"Weight Class\"].map(colors))\n",
    "ax[1].hist(data2[\"BMI\"].dropna(), bins=12, color=\"lightblue\")\n",
    "\n",
    "fig.suptitle(\"Virginia Tech Football: Height, Weight, and BMI\", fontsize=20)\n",
    "ax[0].set_ylabel(\"Weight, pounds\", fontsize=17)\n",
    "ax[0].set_xlabel(\"Height, inches\", fontsize=17)\n",
    "ax[1].set_xlabel(\"BMI\", fontsize=17)\n",
    "ax[1].set_ylabel(\"Number of Players\", fontsize=17)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b02346d",
   "metadata": {},
   "source": [
    "# NOTE: Some visuals may not render depending on your notebook environment. If needed, save figures as images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d77b5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heat map showing height/weight density (Altair)\n",
    "alt.Chart(data2).mark_rect().encode(\n",
    "    alt.X(\"Height, inches:Q\", bin=alt.Bin(maxbins=15)),\n",
    "    alt.Y(\"Weight:Q\", bin=alt.Bin(maxbins=15)),\n",
    "    alt.Color(\"count():Q\", scale=alt.Scale(scheme=\"blues\")),\n",
    ").configure_rect(binSpacing=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075121af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Height and Weight distributions side by side (Altair)\n",
    "height_hist = alt.Chart(data2).mark_bar().encode(\n",
    "    alt.X(\"Height, inches:Q\", bin=alt.Bin(maxbins=15)),\n",
    "    y=\"count()\"\n",
    ")\n",
    "\n",
    "weight_hist = alt.Chart(data2).mark_bar().encode(\n",
    "    alt.X(\"Weight:Q\", bin=alt.Bin(maxbins=15)),\n",
    "    y=\"count()\"\n",
    ")\n",
    "\n",
    "height_hist | weight_hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d99db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of players by State (Altair)\n",
    "alt.Chart(data.dropna(subset=[\"State\"])).mark_bar().encode(\n",
    "    alt.X(\"State:N\", sort=alt.EncodingSortField(field=\"State\", op=\"count\", order=\"descending\")),\n",
    "    alt.Y(\"count():Q\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546e473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory: weight class distribution (matplotlib)\n",
    "plt.hist(data2[\"Weight Class\"])\n",
    "plt.ylabel(\"Number of Players\", fontsize=17)\n",
    "plt.xlabel(\"Weight Class\", fontsize=17)\n",
    "plt.title(\"Number of Players by Weight Class, Virginia Tech Football\")\n",
    "plt.show()\n",
    "\n",
    "# Exploratory: height by weight class\n",
    "plt.scatter(data2[\"Weight Class\"], data2[\"Height, inches\"])\n",
    "plt.ylabel(\"Height, inches\", fontsize=17)\n",
    "plt.xlabel(\"Weight Class\", fontsize=17)\n",
    "plt.title(\"Player Heights (in inches) by Weight Class, Virginia Tech Football\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
